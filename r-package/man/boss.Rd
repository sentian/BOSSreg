% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/boss.R
\name{boss}
\alias{boss}
\title{Best orthogonalized subset selection (BOSS).}
\usage{
boss(x, y, intercept = TRUE, fs.only = FALSE, hdf.ic.boss = TRUE,
  mu = NULL, sigma = NULL, ...)
}
\arguments{
\item{x}{A matrix of predictors, with \code{nrow(x)=length(y)=n} observations and
\code{ncol(x)=p} predictors. Intercept shall not be included.}

\item{y}{A vector of response variable, with \code{length(y)=n}.}

\item{intercept}{Whether to include an intercept term.}

\item{fs.only}{Whether to ignore BOSS and perform FS only.}

\item{hdf.ic.boss}{Whether to calculate the heuristic degrees of freedom (hdf)
and information criteria (IC) for BOSS. IC includes AIC, BIC, AICc, BICc, GCV,
Cp. Note that if the option fs.only=TRUE or n<=p, \code{hdf.ic.boss=FALSE} no matter what.}

\item{mu}{True mean vector, used in the calculation of hdf. Default is NULL, and is estimated via full OLS.}

\item{sigma}{True standard deviation of the error, used in the calculation of hdf. Default is NULL,
and is estimated via full OLS.}

\item{...}{Extra parameters to allow flexibility. Currently none argument allows or requires, just for
the convinience of call from other parent functions like cv.boss.}
}
\value{
\itemize{
  \item beta_fs: A matrix of regression coefficients for each step performed by FS,
  from a null model until stop, with \code{nrow=p} and \code{ncol=min(n,p)+1}, where min(n,p) is
  the maximum number of steps performed.
  \item beta_boss: A matrix of regression coefficients for each step performed by
  BOSS, with \code{nrow=p} and \code{ncol=min(n,p)+1}. Note that unlike beta_fs and due to the nature of BOSS,
  the number of non-zero components in columns of beta_boss may not be unique, i.e.
  there maybe multiple columns corresponding to the same size of subset. \code{beta_boss=NULL}
  if the option \code{fs.only=TRUE}.
  \item steps_fs: A vector of numbers representing which predictor joins at each step,
  with \code{length(steps_fs)=min(n,p)}.
  \item hdf_boss: A vector of heuristic degrees of freedom (hdf) for BOSS, with
  \code{length(hdf_boss)=p+1}. Note that \code{hdf_boss=NULL} if n<=p or \code{hdf.ic.boss=FALSE}.
  \item IC_boss: A list of information criteria (IC) for BOSS, where each element
  in the list is a vector representing values of a given IC for each candidate subset
  of BOSS (or each column in beta_boss). The output IC includes AIC, BIC, AICc, BICc,
  GCV and Mallows' Cp. Note that each IC is calculated by plugging in hdf_boss.

}
}
\description{
\itemize{
 \item Compute the solution path of BOSS and forward stepwise selection (FS).
 \item Compute various information criteria based on a heuristic degrees of freedom
  that can serve as the selection rule to choose the optimal subset given by BOSS.
  Only work when n>p.
}
}
\details{
This function computes the full solution path given by FS and (or) BOSS on a given
  dataset (x,y) with n observations and p predictors. Meanwhile, in the case where n>p, it calculates
  the heuristic degrees of freedom for BOSS, and various information criteria, which can further
  be used to select the optimal candidate along the path. Please refer to the example section below
  for implementation details and Tian et al. (2018) for methodology details.
}
\examples{
## Generate a trivial dataset, X has mean 0 and norm 1, y has mean 0
set.seed(11)
n = 20
p = 5
x = matrix(rnorm(n*p), nrow=n, ncol=p)
x = scale(x, center = colMeans(x))
x = scale(x, scale = sqrt(colSums(x^2)))
beta = c(1, 1, 0, 0, 0)
y = x\%*\%beta + scale(rnorm(n, sd=0.01), center = TRUE, scale = FALSE)

## Fit the model
boss_result = boss(x, y)

## Get the coefficient vector selected by AICc-hdf (S3 method for boss)
beta_boss_aicc = coef(boss_result)$boss
# the above is equivalent to the following
beta_boss_aicc = boss_result$beta_boss[, which.min(boss_result$IC_boss$aicc), drop=FALSE]
## Get the fitted values of BOSS-AICc-hdf (S3 method for boss)
mu_boss_aicc = predict(boss_result, newx=x)$boss
# the above is equivalent to the following
mu_boss_aicc = cbind(1,x) \%*\% beta_boss_aicc

## Repeat the above process, but using Cp-hdf instead of AICc-hdf
## coefficient vector
beta_boss_cp = coef(boss_result, method.boss='cp')$boss
beta_boss_cp = boss_result$beta_boss[, which.min(boss_result$IC_boss$cp), drop=FALSE]
## fitted values of BOSS-Cp-hdf
mu_boss_cp = predict(boss_result, newx=x, method.boss='cp')$boss
mu_boss_cp = cbind(1,x) \%*\% beta_boss_cp
}
\references{
Tian, Hurvich and Simonoff (2019), On the use of information criterion
  in least squares based subset selection problems. (Link to be added)
}
\seealso{
\code{predict} and  \code{coef} methods for "boss" object, and the \code{cv.boss} function
}
\author{
Sen Tian
}
